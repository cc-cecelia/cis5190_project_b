# 519 final ä»»åŠ¡ä¹¦ï¼šäºŒåˆ†ç±»æ–°é—»æ ‡é¢˜
github: 
## æ–‡ä»¶ç»“æ„

```markdown
cis5190_project_b/
â”‚
â”œâ”€â”€ ğŸ“Š data/                                (æ•°æ®å­˜å‚¨ç›®å½•)
â”‚   â”œâ”€â”€ raw/                                (åŸå§‹æ•°æ®)
â”‚   â”‚   â”œâ”€â”€ urls_initial.csv                (è€å¸ˆæä¾›çš„åˆå§‹ URL åˆ—è¡¨)
â”‚   â”‚   â””â”€â”€ urls_collected_partX.csv        (æ”¶é›†çš„é¢å¤– URL)
â”‚   â”œâ”€â”€ processed/                          (æ¸…ç†å’Œåˆ’åˆ†åçš„æ•°æ®é›†)
â”‚   â”‚   â”œâ”€â”€ processed_data.csv              (æ‰€æœ‰æ•°æ®æ ‡é¢˜å’Œæ ‡ç­¾)
â”‚   â”‚   â”œâ”€â”€ train_data.csv                  (è®­ç»ƒé›†æ ‡é¢˜å’Œæ ‡ç­¾)
â”‚   â”‚   â”œâ”€â”€ validation_data.csv             (éªŒè¯é›†æ ‡é¢˜å’Œæ ‡ç­¾)
â”‚   â”‚   â””â”€â”€ my_test_data.csv                (å†…éƒ¨æµ‹è¯•é›†åˆ)
â”‚   â”‚
â”‚   â””â”€â”€ hf_dataset_link.txt                 (è®°å½•æœ€ç»ˆ Hugging Face Dataset çš„é“¾æ¥)
â”‚
â”œâ”€â”€ âš™ï¸ src/                                 (æ ¸å¿ƒä»£ç ç›®å½•)
â”‚   â”œâ”€â”€ baseline/                           (åŸºçº¿æ¨¡å‹æƒé‡/ç»“æœ)
â”‚   â”‚   â”œâ”€â”€ logistic è®­ç»ƒä»£ç              	 
â”‚   â”‚   â””â”€â”€ logistic æƒé‡
â”‚   â”œâ”€â”€ ğŸ”‘ preprocess.py                    (ã€å¿…é¡»æäº¤ã€‘å¤„ç†åˆ†è¯/ç‰¹å¾æå–)
â”‚   â”œâ”€â”€ ğŸ”‘ model.py                         (ã€å¿…é¡»æäº¤ã€‘å®ç°æœ€ä½³æ¨¡å‹æ¶æ„)
â”‚   â”œâ”€â”€ train.py                            (è®­ç»ƒä¸»è„šæœ¬)
â”‚   â””â”€â”€ utils.py                            (è¾…åŠ©å‡½æ•°)
â”‚
â”œâ”€â”€ ğŸ’¾ models/                              (æ¨¡å‹æƒé‡å’Œæ£€æŸ¥ç‚¹ç›®å½•)
â”‚   â”œâ”€â”€ weights/     
â”‚   â”‚   â”œâ”€â”€ XXX_model.pt                    (ä¸åŒoptionalè®­ç»ƒå‡ºæ¥çš„weight)
â”‚   â”‚   â””â”€â”€ ğŸ”‘ model.pt                     (ã€å¿…é¡»æäº¤ã€‘æœ€ä½³æ¨¡å‹çš„æƒé‡æ–‡ä»¶)  
â”‚   â”œâ”€â”€ logs/                               (ä¸“é—¨æ”¾è®­ç»ƒè¿‡ç¨‹çš„æ•°æ®åŒ…æ‹¬losså’Œaccï¼Œç”¨äºç»˜å›¾)
â”‚       â”œâ”€â”€ bert_history.json
â”‚       â””â”€â”€ baseline_history.json
â”‚   â””â”€â”€ dapt_checkpoints/                   (Domain-Adaptive Pretraining ä¸­é—´æ£€æŸ¥ç‚¹)
â”‚
â”œâ”€â”€ ğŸ““ experiments/                         (Jupyter Notebooks å®éªŒç»˜å›¾è®°å½•)
â”‚   â””â”€â”€ plot.ipynb                          (æ¨¡å‹å¾®è°ƒã€Ablation Study å’Œå›¾è¡¨ç”Ÿæˆè®°å½•ï¼Œå¯ä»¥å†åˆ†ä¸åŒæ–‡ä»¶)
â”‚
â”œâ”€â”€ ğŸ“ˆ figures/                             (æŠ¥å‘Šå›¾è¡¨ç›®å½•)
â”‚   â”œâ”€â”€ accuracy_curve.png                  (ä¸åŒæ¨¡å‹å‡†ç¡®ç‡çš„æŠ˜çº¿å›¾ï¼Œè¿™ä¸ªéšæ„å§)
â”‚   â””â”€â”€ loss_history.png                    (è®­ç»ƒ Loss æ›²çº¿)
â”‚
â”œâ”€â”€ .gitignore                              (Git å¿½ç•¥æ–‡ä»¶)
â”œâ”€â”€ requirements.txt                        (Python ç¯å¢ƒä¾èµ–åˆ—è¡¨)
â”œâ”€â”€ ğŸ“„ final_report.pdf                     (ã€å¿…é¡»æäº¤ã€‘é¡¹ç›®æŠ¥å‘Šï¼Œ5é¡µ)
â””â”€â”€ eval_project_b.py                       (è€å¸ˆæä¾›çš„æœ¬åœ°è¯„ä¼°è„šæœ¬ï¼Œä¸æäº¤)
```

## ä»»åŠ¡æµç¨‹

### é˜¶æ®µ 1: æ•°æ®å‡†å¤‡

1. **æ•°æ®çˆ¬å–ä¸åˆæ­¥æ¸…ç†**:
   - ä½¿ç”¨`urls_initial.csv`å’Œè‡ªè¡Œæ”¶é›†çš„ URLï¼Œç¼–å†™çˆ¬è™«ï¼ˆ`01_data_scraping.ipynb`ï¼‰æ¥è·å–æ–°é—»æ ‡é¢˜å’Œå¯¹åº”çš„æ¥æºæ ‡ç­¾ ã€‚
   - è¾“å‡ºå½¢å¼ï¼šã€titleã€‘ã€labelã€‘
     - Titleç§»é™¤ HTML æ ‡ç­¾ã€ç‰¹æ®Šå­—ç¬¦ã€ç»Ÿä¸€ä¸ºå°å†™ã€ç§»é™¤é‡å¤æ ‡é¢˜
     - æ ‡ç­¾è½¬æ¢è½¬æ¢ä¸ºäºŒå…ƒæ•°å€¼ï¼š0 ä»£è¡¨ Fox Newsï¼Œ1 ä»£è¡¨ NBC News ï¼‰ã€‚
     - æ•°æ®é›†`processed_data.csv`æ‹†åˆ†ä¸ºè®­ç»ƒé›†`train_data.csv`ã€éªŒè¯é›†`validation_data.csv`å’Œå†…éƒ¨æµ‹è¯•é›†`my_test_data.csv` ã€‚
2. **åŸºçº¿é‡è·‘**:
   - ä½¿ç”¨ TF-IDF + Logistic Regression é‡å»ºåŸºçº¿æ¨¡å‹ï¼ˆè§ç¬¬10é¡µï¼‰ï¼Œç¡®è®¤æ•°æ®é›†è´¨é‡å¹¶è®°å½• $0.6649$ é™„è¿‘çš„å‡†ç¡®ç‡ 
3. **I/O åˆåŒå®ç°**
   - `preprocess.py/ prepare_data(csv_path)` ï¼šæ•°æ®æ¸…æ´—ï¼Œè½¬æˆTensor çš„ text
   -  `model.py/ predict(self, batch: Iterable[Any]) -> List[Any]:` è®°å¾—å…ˆtokenize

### é˜¶æ®µ 2: æ¨¡å‹æ„å»ºä¸ä¼˜åŒ– 

1. **è½¬åŒ–è¾“å…¥`preprocess.py` **:
   - ç”¨DistilBertçš„Tokenizer åˆ†è¯ï¼Œæ·»åŠ ç‰¹æ®Šæ ‡è®°ï¼Œpadding

2. **åˆå§‹æ¨¡å‹å¾®è°ƒ ** `train.py`, `model.py`:

   - åŠ è½½é¢„è®­ç»ƒçš„ DistilBERT æ¨¡å‹
   - åœ¨é¡¶å±‚åŠ ä¸Šçº¿æ€§åˆ†ç±»å™¨
   - å¾®è°ƒ`train.py args` ç¡®è®¤æ˜¯å¦end to end æˆ–è€… ä»…å¾®è°ƒ åˆ†ç±»å±‚ã€å‚æ•°å¯é€‰ `utils.py` ã€‘

   - ä¿å­˜æœ€ä½³æƒé‡åˆ° `models/model.pt`ã€‚

3. **é«˜çº§ä¼˜åŒ– **: å°è¯• **Domain-Adaptive Pretraining (DAPT)** æˆ– **ç‰¹å¾æ‹¼æ¥**ï¼ˆTF-IDF + BERT è¾“å‡ºï¼‰ï¼Œå¹¶å°†ç»“æœè®°å½•ä¸‹æ¥ã€‚

   - è®­ç»ƒå±‚é¢ä¼˜åŒ–ã€å‚æ•°å¯é€‰ `utils.py` ã€‘ï¼šåŠ å…¥ **Domain-Adaptive Pretraining (DAPT)** 

     -  Unsupervised: è®© BERT çš„è¯å‘é‡å’Œæ³¨æ„åŠ›æ›´è´´è¿‘æ–°é—»æ ‡é¢˜é¢†åŸŸ

     - `train.py`: å¾®è°ƒæ‰€å¤„ä½ç½®ï¼šDAPT -then- Finetune 

     - ```
       loss = MLM_loss # cross entropy
       loss.backward() # æ›´æ–° BERT å‚æ•° embedding layer, transformer layers, attention weights
       ```

   - ã€âŒ,å…ˆå¾…å®šï¼Œåªåœ¨logistic regressionä¸­ç”¨ï¼Œå› ä¸ºæˆ‘æ²¡ææ˜ç™½åˆ°åº•åœ¨å“ªç”¨ä»¥åŠä»–å¯¹è®­ç»ƒå±‚é¢çš„å½±å“ã€‘ç‰¹å¾å·¥ç¨‹å±‚é¢ä¼˜åŒ–ã€å‚æ•°å¯é€‰ `utils.py` ã€‘ï¼šç‰¹å¾æ‹¼æ¥ **TF-IDF** ï¼Œå­¦ä¹ æ–°é—»é£æ ¼

     - `preprocess.py`: æ ‡é¢˜ç”Ÿæˆ TF-IDFï¼ˆ512ç»´ï¼Œä¿å­˜ä¸º `sample["tfidf"] = tensor(512,)`

     - `model.py`:  `forward()` ï½ï½ï½å­˜ç–‘

       ```
       cls_vector = BERT(title)
       combined = concat(cls_vector, tfidf)
       logits = classifier(combined)
       ```

4. è¿è¡Œ **Ablation Study**ï¼šå¯¹æ¯”ä¸åŒä¼˜åŒ–æ­¥éª¤ï¼ˆBaseline -> DistilBERT -> DistilBERT + DAPTï¼‰çš„æ€§èƒ½ï¼Œç”ŸæˆæŠ¥å‘Šæ‰€éœ€çš„æŠ˜çº¿å›¾å’Œæ•°æ®ã€‚

```
crawler.py + processing.py/prepare_data: æ•°æ®æ¸…æ´—
						ğŸ‘‡
 [DATA] dataset:  {{title, label}}	# Tuple[torch.Tensor, torch.Tensor] ğŸ‘‰ model.py/predict
						ğŸ‘‡
processing.py/class Dataset/__getitem__: tokenize
						ğŸ‘‡
			[DATA] tokens
						ğŸ‘‡
  train.py/init self.embedding
 						ğŸ‘‡
 train.py/(optional) DAPT + classifier + (optional)transformer
  					ğŸ‘‡
  	 [DATA] model.pt
  	 				ğŸ‘‡
  		model.py/pridict/tokenize + predict ğŸ‘ˆ [DATA] {{title, label}} from prepare_data
  					ğŸ‘‡
  		[DATA] output / metrics
```

### é˜¶æ®µ 3: è¯„ä¼°ä¸æäº¤ 

1. ä½¿ç”¨`eval_project_b.py` è„šæœ¬ï¼Œå°†`preprocess.py`ã€`model.py` å’Œ `model.pt` æ”¾åœ¨ä¸€èµ·è¿›è¡Œ**æœ¬åœ°æµ‹è¯•** ï¼Œç¡®ä¿ I/Oã€‚
2. åˆ›å»º **Hugging Face Dataset** å¹¶ä¸Šä¼ æ”¶é›†çš„æ•°æ®ã€‚
3. **æŠ¥å‘Šæ’°å†™ä¸æœ€ç»ˆæäº¤ **:

- æ’°å†™å¹¶æ ¼å¼åŒ– 5 é¡µçš„é¡¹ç›®æŠ¥å‘Š (`final_report.pdf`)ï¼Œé™„å¸¦æ¸…æ™°çš„å›¾è¡¨ï¼ˆæŠ˜çº¿å›¾ã€Loss æ›²çº¿ï¼‰å’Œ Ablation Study ç»“æœã€‚
- æäº¤æ‰€æœ‰æ–‡ä»¶ +  Hugging Face Dataset é“¾æ¥(in report)ã€‚
- å°†æœ€ä½³æ¨¡å‹æäº¤åˆ° Hugging Face æ’è¡Œæ¦œè¿›è¡Œæœ€ç»ˆè¯„ä¼° ã€‚