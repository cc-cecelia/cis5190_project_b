import subprocess
import os
import sys
import time
import datetime


def run_command(command, log_name):
    """
    æ‰§è¡Œå‘½ä»¤ï¼Œå®æ—¶æ‰“å°è¾“å‡ºå¹¶ä¿å­˜åˆ° logs æ–‡ä»¶å¤¹ã€‚
    """
    log_dir = "../models/temp_logs/bash"
    if not os.path.exists(log_dir):
        os.makedirs(log_dir)

    timestamp = datetime.datetime.now().strftime("%Y%m%d_%H%M")
    log_path = f"{log_dir}/{log_name}_{timestamp}.log"

    print(f"\n{'=' * 80}")
    print(f"ğŸš€ [START] {log_name}")
    print(f"ğŸ“„ Log: {log_path}")
    print(f"âŒ¨ï¸  Cmd: {command}")
    print(f"{'=' * 80}\n")

    start_time = time.time()

    my_env = os.environ.copy()
    my_env["PYTHONUNBUFFERED"] = "1"

    with open(log_path, "w") as f:
        process = subprocess.Popen(
            command,
            shell=True,
            stdout=subprocess.PIPE,
            stderr=subprocess.STDOUT,  # æŠŠé”™è¯¯ä¹Ÿé‡å®šå‘åˆ°æ ‡å‡†è¾“å‡ºï¼Œé˜²æ­¢é”™ä½
            text=True,
            bufsize=1,
            universal_newlines=True,
            env=my_env
        )

        # ã€å…³é”®ä¿®æ”¹ 3ã€‘ä½¿ç”¨ readline() å¾ªç¯è¯»å–ï¼Œå¹¶æ‰‹åŠ¨ flush
        while True:
            line = process.stdout.readline()
            if not line and process.poll() is not None:
                break
            if line:
                # æ‰“å°åˆ°å±å¹•å¹¶å¼ºåˆ¶åˆ·æ–°
                sys.stdout.write(line)
                sys.stdout.flush()
                # å†™å…¥æ–‡ä»¶å¹¶å¼ºåˆ¶åˆ·æ–°
                f.write(line)
                f.flush()

    duration = (time.time() - start_time) / 60

    if process.returncode != 0:
        print(f"\nâŒ [FAILED] {log_name} (Duration: {duration:.2f} min)")
        print(f"Check log file: {log_path}")
        # å¦‚æœ DAPT æŒ‚äº†ï¼Œåé¢ä¾èµ–å®ƒçš„å®éªŒä¹Ÿä¼šæŒ‚ï¼Œæ‰€ä»¥ç›´æ¥é€€å‡ºæ¯”è¾ƒå®‰å…¨
        if "dapt" in log_name:
            print("CRITICAL: DAPT phase failed. Aborting subsequent experiments.")
            sys.exit(1)
    else:
        print(f"\nâœ… [SUCCESS] {log_name} (Duration: {duration:.2f} min)")


def main():
    # æ£€æŸ¥å½“å‰ç›®å½•
    if os.path.basename(os.getcwd()) != "src":
        print("âš ï¸  è¯·åœ¨ 'src' ç›®å½•ä¸‹è¿è¡Œæ­¤è„šæœ¬ï¼")
        sys.exit(1)

    print("ğŸ›Œ å¯åŠ¨å…¨è‡ªåŠ¨ Ablation Study (Two-Stage Epochs Supported) æµç¨‹...")
    total_start = time.time()

    # ==========================================
    # 1. Baseline: Logistic Regression
    # ==========================================
    # run_command(
    #     "python baseline/train_baseline.py --max_features 5000 --ngram_range 1 2 --C 1.0",
    #     "00_baseline_logistic"
    # )

    # ==========================================
    # 2. Exp 1: DistilBERT (Frozen)
    # ==========================================
    # ç­–ç•¥ï¼šå†»ç»“ Encoderï¼Œåªè®­ç»ƒ Classifier
    # æ³¨æ„ï¼šFrozen æ¨¡å¼ä¸‹ï¼Œwarmup å‚æ•°å¿…é¡»ä¼ 
    # for batch_size in [8, 16, 32, 64]:
    #     for dropout in [0.1, 0.3, 0.5]:
    #         run_command(
    #             "python train.py --freeze_encoder --warm_lr 2e-5 --batch_size 16 --warm_ep 5 --dropout 0.1 --memo \"15k\"",
    #             f"01_exp1_frozen_baseline_bs{batch_size}_do{str(int(dropout*10))}"
    #         )

    # best_batch = 16 #
    # best_dropout = 0.1 #

    # ==========================================
    # 3. DAPT Phase (Pre-training)
    # ==========================================
    # è¿™æ˜¯ Exp 2 å’Œ Exp 4 çš„å‰ç½®æ¡ä»¶ DONE
    run_command(
        "python train_dapt.py --lr 3e-5 --batch_size 16 --epochs 3 --memo \"large\" --csv_name processed_data_large.csv",
        "02_dapt_pretraining"
    )

    # ==========================================
    # 4. Exp 2: DistilBERT + DAPT (Frozen)
    # ==========================================
    # ç­–ç•¥ï¼šåŠ è½½ DAPT æƒé‡ï¼Œä½†ä¾ç„¶å†»ç»“ Encoder
    # for warm_lr in [1e-5, 2e-5, 3e-5]:
    #     run_command(
    #         f"python train.py --use_dapt --checkpoint dapt_lr3e5_ep3_15k_backbone --freeze_encoder --warm_lr {warm_lr} --batch_size {best_batch} --warm_ep 5 --dropout {best_dropout} --memo \"15k\"",
    #         f"03_exp2_dapt_frozen_{warm_lr}"
    #     )

    # ==========================================
    # 5. Exp 3: DistilBERT (Two-Stage Fine-tuning)
    # ==========================================
    # ç­–ç•¥ï¼šä¸¤é˜¶æ®µå¾®è°ƒ (ä¸åŠ  DAPT)
    # é˜¶æ®µ1: 3è½® Warmup (lr=1e-4)
    # é˜¶æ®µ2: 5è½® Full FT (lr=2e-5)
    # run_command(
    #     "python train.py --bert_lr 2e-5 --warm_lr 1e-4 --warm_ep 3 --bert_ep 5 --batch_size 16 --dropout 0.1 --memo \"3k8\"",
    #     "04_exp3_finetune_twostage"
    # )

    # ==========================================
    # 6. Exp 4: DistilBERT + DAPT (Two-Stage Fine-tuning)
    # ==========================================
    # ç­–ç•¥ï¼šåŠ è½½ DAPT æƒé‡ + ä¸¤é˜¶æ®µå¾®è°ƒ
    # é˜¶æ®µ1: 3è½® Warmup (lr=1e-4)
    # é˜¶æ®µ2: 5è½® Full FT (lr=2e-5)
    run_command(
        "python train.py --use_dapt --checkpoint dapt_lr3e05_ep3_large_backbone --bert_lr 2e-5 --warm_lr 1e-4 --warm_ep 3 --bert_ep 5 --batch_size 16 --dropout 0.1  --memo \"large\" --csv_name processed_data_large.csv",
        "05_exp4_dapt_finetune_twostage"
    )

    total_duration = (time.time() - total_start) / 60
    print(f"\nğŸ‰ğŸ‰ğŸ‰ æ‰€æœ‰ä»»åŠ¡æ‰§è¡Œå®Œæ¯•ï¼å¤§å®¶æ™šå®‰ï¼")
    print(f"æ€»è€—æ—¶: {total_duration:.2f} åˆ†é’Ÿ")


if __name__ == "__main__":
    main()